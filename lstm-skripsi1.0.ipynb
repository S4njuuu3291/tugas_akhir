{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13870537,"sourceType":"datasetVersion","datasetId":8833146}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.bin.gz\n!gunzip cc.id.300.bin.gz","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T10:04:28.509399Z","iopub.execute_input":"2025-11-28T10:04:28.509700Z"}},"outputs":[{"name":"stdout","text":"--2025-11-28 10:04:28--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.bin.gz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.225.143.54, 13.225.143.99, 13.225.143.109, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.225.143.54|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4507049071 (4.2G) [application/octet-stream]\nSaving to: ‘cc.id.300.bin.gz’\n\ncc.id.300.bin.gz    100%[===================>]   4.20G   243MB/s    in 18s     \n\n2025-11-28 10:04:46 (242 MB/s) - ‘cc.id.300.bin.gz’ saved [4507049071/4507049071]\n\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"from gensim.models import KeyedVectors\n\nft = KeyedVectors.load_facebook_model(\"cc.id.300.vec\", binary=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T00:37:25.581293Z","iopub.execute_input":"2025-11-26T00:37:25.581570Z","iopub.status.idle":"2025-11-26T00:46:30.623931Z","shell.execute_reply.started":"2025-11-26T00:37:25.581545Z","shell.execute_reply":"2025-11-26T00:46:30.623090Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\nfrom sklearn.metrics import classification_report\n\ndf = pd.read_csv(\"/kaggle/input/datasethatespeechmultilabel/clean_data.csv\")\ndf = df.dropna()\nX = df[\"Tweet\"]\ny = df.drop([\"Tweet\", \"num_labels\"], axis=1)\n\nsss = MultilabelStratifiedShuffleSplit(\n    n_splits=1,\n    test_size=0.2,\n    random_state=42\n)\n\nfor train_idx, test_idx in sss.split(X, y):\n    X_train = X.iloc[train_idx]\n    X_test = X.iloc[test_idx]\n    y_train = y.iloc[train_idx]\n    y_test = y.iloc[test_idx]\n\nprint(\"Proporsi label train:\")\nprint(y_train.mean())\n\nprint(\"\\nProporsi label test:\")\nprint(y_test.mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T01:25:58.796710Z","iopub.execute_input":"2025-11-26T01:25:58.797251Z","iopub.status.idle":"2025-11-26T01:25:58.987163Z","shell.execute_reply.started":"2025-11-26T01:25:58.797216Z","shell.execute_reply":"2025-11-26T01:25:58.986498Z"}},"outputs":[{"name":"stdout","text":"Proporsi label train:\nHS_Individual    0.271706\nHS_Group         0.151181\nHS_Religion      0.060358\nHS_Race          0.043126\nHS_Physical      0.024562\nHS_Gender        0.023324\ndtype: float64\n\nProporsi label test:\nHS_Individual    0.271896\nHS_Group         0.151181\nHS_Religion      0.060548\nHS_Race          0.043031\nHS_Physical      0.024752\nHS_Gender        0.023229\ndtype: float64\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nmax_words = 35000\ntokenizer = Tokenizer(num_words=max_words, oov_token=\"<unk>\")\ntokenizer.fit_on_texts(X_train)\n\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_test_seq  = tokenizer.texts_to_sequences(X_test)\n\nmax_len = 50\nX_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\nX_test_pad  = pad_sequences(X_test_seq, maxlen=max_len)\n\nnum_labels = y_train.shape[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T01:15:07.427470Z","iopub.execute_input":"2025-11-26T01:15:07.427777Z","iopub.status.idle":"2025-11-26T01:15:07.766716Z","shell.execute_reply.started":"2025-11-26T01:15:07.427760Z","shell.execute_reply":"2025-11-26T01:15:07.766074Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"import numpy as np\n\nembedding_dim = 300\nword_index = tokenizer.word_index\nembedding_matrix = np.zeros((max_words, embedding_dim))\n\nfor word, idx in word_index.items():\n    if idx >= max_words:\n        continue\n    if word in ft:\n        embedding_matrix[idx] = ft[word]\n    else:\n        embedding_matrix[idx] = np.zeros(embedding_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T01:15:07.767566Z","iopub.execute_input":"2025-11-26T01:15:07.767841Z","iopub.status.idle":"2025-11-26T01:15:07.854127Z","shell.execute_reply.started":"2025-11-26T01:15:07.767817Z","shell.execute_reply":"2025-11-26T01:15:07.853522Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.callbacks import Callback\n\ndef exact_match_ratio(actual, pred):\n    actual = np.array(actual)\n    pred   = np.array(pred)\n    return np.mean(np.all(actual == pred, axis=1))\n\ndef hamming_loss_(actual, pred):\n    actual = np.array(actual)\n    pred   = np.array(pred)\n    N, L   = actual.shape\n\n    diff = actual != pred\n    return diff.sum() / (N * L)\n\ndef micro_f1(actual, pred):\n    actual = np.array(actual)\n    pred   = np.array(pred)\n\n    TP = np.sum((actual == 1) & (pred == 1))\n    FP = np.sum((actual == 0) & (pred == 1))\n    FN = np.sum((actual == 1) & (pred == 0))\n\n    if TP == 0:\n        return 0.0\n\n    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n    recall    = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n\n    if precision + recall == 0:\n        return 0.0\n\n    return 2 * precision * recall / (precision + recall)\n\ndef macro_f1(actual, pred):\n    actual = np.array(actual)\n    pred   = np.array(pred)\n\n    L = actual.shape[1]\n    f1_scores = []\n\n    for j in range(L):\n        y_true = actual[:, j]\n        y_pred = pred[:, j]\n\n        TP = np.sum((y_true == 1) & (y_pred == 1))\n        FP = np.sum((y_true == 0) & (y_pred == 1))\n        FN = np.sum((y_true == 1) & (y_pred == 0))\n\n        precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n        recall    = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n\n        if precision + recall > 0:\n            f1 = 2 * precision * recall / (precision + recall)\n        else:\n            f1 = 0.0\n\n        f1_scores.append(f1)\n\n    return np.mean(f1_scores)\n\nclass MultiLabelMetrics(Callback):\n    def __init__(self, X_val, y_val):\n        super().__init__()\n        self.X_val = X_val\n        self.y_val = y_val\n\n    def on_epoch_end(self, epoch, logs=None):\n        y_prob = self.model.predict(self.X_val, verbose=0)\n        y_pred = (y_prob > 0.5).astype(int)\n\n        emr = exact_match_ratio(self.y_val, y_pred)\n        ham = hamming_loss_(self.y_val, y_pred)\n        mic = micro_f1(self.y_val, y_pred)\n        mac = macro_f1(self.y_val, y_pred)\n\n        print(f\" — val_exact_match: {emr:.4f} — val_hamming: {ham:.4f} — val_micro_f1: {mic:.4f} — val_macro_f1: {mac:.4f}\")\n\n        logs[\"val_exact_match\"] = emr\n        logs[\"val_hamming_loss\"] = ham\n        logs[\"val_micro_f1\"] = mic\n        logs[\"val_macro_f1\"] = mac","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T01:15:07.855872Z","iopub.execute_input":"2025-11-26T01:15:07.856070Z","iopub.status.idle":"2025-11-26T01:15:07.868958Z","shell.execute_reply.started":"2025-11-26T01:15:07.856055Z","shell.execute_reply":"2025-11-26T01:15:07.868416Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n\nmodel = Sequential()\n\nmodel.add(\n    Embedding(\n        input_dim=max_words,\n        output_dim=embedding_dim,\n        weights=[embedding_matrix],\n        input_length=max_len,\n        trainable=False\n    )\n)\n\nmodel.add(Dropout(0.25))\n\nmodel.add(\n    Bidirectional(\n        LSTM(256, dropout=0.3, recurrent_dropout=0.2)\n    )\n)\n\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(num_labels, activation=\"sigmoid\"))\n\nmodel.compile(\n    loss=\"binary_crossentropy\",\n    optimizer=\"adam\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T01:19:56.072010Z","iopub.execute_input":"2025-11-26T01:19:56.072837Z","iopub.status.idle":"2025-11-26T01:19:56.198153Z","shell.execute_reply.started":"2025-11-26T01:19:56.072809Z","shell.execute_reply":"2025-11-26T01:19:56.197274Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":75},{"cell_type":"code","source":"for train_idx, test_idx in sss.split(X_train_pad, y_train):\n    X_train_final = X_train_pad[train_idx] \n    X_val_final   = X_train_pad[test_idx]   \n\n    y_train_final = y_train.iloc[train_idx]\n    y_val_final   = y_train.iloc[test_idx] \n\n\nmetrics_callback = MultiLabelMetrics(X_val_final, y_val_final)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T01:19:58.185143Z","iopub.execute_input":"2025-11-26T01:19:58.185898Z","iopub.status.idle":"2025-11-26T01:19:58.307265Z","shell.execute_reply.started":"2025-11-26T01:19:58.185864Z","shell.execute_reply":"2025-11-26T01:19:58.306436Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"history = model.fit(\n    X_train_final,\n    y_train_final,\n    validation_data=(X_val_final, y_val_final),\n    epochs=10,\n    batch_size=64,\n    callbacks=[metrics_callback],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T01:20:00.535860Z","iopub.execute_input":"2025-11-26T01:20:00.536159Z","iopub.status.idle":"2025-11-26T01:24:34.648916Z","shell.execute_reply.started":"2025-11-26T01:20:00.536134Z","shell.execute_reply":"2025-11-26T01:24:34.648283Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.3588 — val_exact_match: 0.5769 — val_hamming: 0.0958 — val_micro_f1: 0.0000 — val_macro_f1: 0.0000\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 214ms/step - loss: 0.3583 - val_loss: 0.2610 - val_exact_match: 0.5769 - val_hamming_loss: 0.0958 - val_micro_f1: 0.0000e+00 - val_macro_f1: 0.0000e+00\nEpoch 2/10\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.2567 — val_exact_match: 0.6030 — val_hamming: 0.0888 — val_micro_f1: 0.1849 — val_macro_f1: 0.1458\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 198ms/step - loss: 0.2566 - val_loss: 0.2282 - val_exact_match: 0.6030 - val_hamming_loss: 0.0888 - val_micro_f1: 0.1849 - val_macro_f1: 0.1458\nEpoch 3/10\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.2338 — val_exact_match: 0.6092 — val_hamming: 0.0871 — val_micro_f1: 0.2448 — val_macro_f1: 0.2014\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 199ms/step - loss: 0.2338 - val_loss: 0.2138 - val_exact_match: 0.6092 - val_hamming_loss: 0.0871 - val_micro_f1: 0.2448 - val_macro_f1: 0.2014\nEpoch 4/10\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.2183 — val_exact_match: 0.6230 — val_hamming: 0.0847 — val_micro_f1: 0.3101 — val_macro_f1: 0.2440\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 199ms/step - loss: 0.2183 - val_loss: 0.2076 - val_exact_match: 0.6230 - val_hamming_loss: 0.0847 - val_micro_f1: 0.3101 - val_macro_f1: 0.2440\nEpoch 5/10\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.2094 — val_exact_match: 0.6545 — val_hamming: 0.0793 — val_micro_f1: 0.4200 — val_macro_f1: 0.2784\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 199ms/step - loss: 0.2094 - val_loss: 0.1989 - val_exact_match: 0.6545 - val_hamming_loss: 0.0793 - val_micro_f1: 0.4200 - val_macro_f1: 0.2784\nEpoch 6/10\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.2051 — val_exact_match: 0.6673 — val_hamming: 0.0764 — val_micro_f1: 0.4891 — val_macro_f1: 0.3438\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 202ms/step - loss: 0.2050 - val_loss: 0.1950 - val_exact_match: 0.6673 - val_hamming_loss: 0.0764 - val_micro_f1: 0.4891 - val_macro_f1: 0.3438\nEpoch 7/10\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.2064 — val_exact_match: 0.6583 — val_hamming: 0.0766 — val_micro_f1: 0.4710 — val_macro_f1: 0.3285\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 201ms/step - loss: 0.2063 - val_loss: 0.1902 - val_exact_match: 0.6583 - val_hamming_loss: 0.0766 - val_micro_f1: 0.4710 - val_macro_f1: 0.3285\nEpoch 8/10\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.1906 — val_exact_match: 0.6721 — val_hamming: 0.0735 — val_micro_f1: 0.5108 — val_macro_f1: 0.3521\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 203ms/step - loss: 0.1906 - val_loss: 0.1827 - val_exact_match: 0.6721 - val_hamming_loss: 0.0735 - val_micro_f1: 0.5108 - val_macro_f1: 0.3521\nEpoch 9/10\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.1878 — val_exact_match: 0.6797 — val_hamming: 0.0727 — val_micro_f1: 0.5519 — val_macro_f1: 0.4006\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 205ms/step - loss: 0.1878 - val_loss: 0.1791 - val_exact_match: 0.6797 - val_hamming_loss: 0.0727 - val_micro_f1: 0.5519 - val_macro_f1: 0.4006\nEpoch 10/10\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.1819 — val_exact_match: 0.6844 — val_hamming: 0.0719 — val_micro_f1: 0.5259 — val_macro_f1: 0.3820\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 203ms/step - loss: 0.1819 - val_loss: 0.1792 - val_exact_match: 0.6844 - val_hamming_loss: 0.0719 - val_micro_f1: 0.5259 - val_macro_f1: 0.3820\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"y_pred_probs = model.predict(X_test_pad)\ny_pred = (y_pred_probs > 0.5).astype(int)\n\nprint(\"Exact Match Ratio:\", exact_match_ratio(y_test, y_pred))\nprint(\"Hamming Loss:\", hamming_loss_(y_test, y_pred))\nprint(\"Micro F1:\", micro_f1(y_test, y_pred))\nprint(\"Macro F1:\", macro_f1(y_test, y_pred))\nprint(\"Classification Report:\",classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T01:26:09.151925Z","iopub.execute_input":"2025-11-26T01:26:09.152424Z","iopub.status.idle":"2025-11-26T01:26:12.405312Z","shell.execute_reply.started":"2025-11-26T01:26:09.152403Z","shell.execute_reply":"2025-11-26T01:26:12.404492Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step\nExact Match Ratio: 0.6881188118811881\nHamming Loss: 0.06968773800456969\nMicro F1: 0.5315699658703071\nMacro F1: 0.4214444903818184\nClassification Report:               precision    recall  f1-score   support\n\n           0       0.74      0.45      0.56       714\n           1       0.76      0.37      0.49       397\n           2       0.79      0.41      0.54       159\n           3       0.69      0.72      0.70       113\n           4       0.00      0.00      0.00        65\n           5       0.89      0.13      0.23        61\n\n   micro avg       0.75      0.41      0.53      1509\n   macro avg       0.65      0.35      0.42      1509\nweighted avg       0.72      0.41      0.52      1509\n samples avg       0.19      0.17      0.18      1509\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}