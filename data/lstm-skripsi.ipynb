{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13870537,"sourceType":"datasetVersion","datasetId":8833146}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.vec.gz\n!gunzip cc.id.300.vec.gz","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-26T00:36:51.602988Z","iopub.execute_input":"2025-11-26T00:36:51.603303Z","iopub.status.idle":"2025-11-26T00:37:25.579664Z","shell.execute_reply.started":"2025-11-26T00:36:51.603279Z","shell.execute_reply":"2025-11-26T00:37:25.578656Z"}},"outputs":[{"name":"stdout","text":"--2025-11-26 00:36:51--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.vec.gz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.51, 3.163.189.14, 3.163.189.108, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.51|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1227018698 (1.1G) [binary/octet-stream]\nSaving to: ‘cc.id.300.vec.gz’\n\ncc.id.300.vec.gz    100%[===================>]   1.14G   272MB/s    in 4.2s    \n\n2025-11-26 00:36:56 (276 MB/s) - ‘cc.id.300.vec.gz’ saved [1227018698/1227018698]\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from gensim.models import KeyedVectors\n\nft = KeyedVectors.load_word2vec_format(\"cc.id.300.vec\", binary=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T00:37:25.581293Z","iopub.execute_input":"2025-11-26T00:37:25.581570Z","iopub.status.idle":"2025-11-26T00:46:30.623931Z","shell.execute_reply.started":"2025-11-26T00:37:25.581545Z","shell.execute_reply":"2025-11-26T00:46:30.623090Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n\ndf = pd.read_csv(\"/kaggle/input/datasethatespeechmultilabel/clean_data.csv\")\ndf = df.dropna()\nX = df[\"Tweet\"]\ny = df.drop([\"Tweet\", \"num_labels\"], axis=1)\n\nsss = MultilabelStratifiedShuffleSplit(\n    n_splits=1,\n    test_size=0.2,\n    random_state=42\n)\n\nfor train_idx, test_idx in sss.split(X, y):\n    X_train = X.iloc[train_idx]\n    X_test = X.iloc[test_idx]\n    y_train = y.iloc[train_idx]\n    y_test = y.iloc[test_idx]\n\nprint(\"Proporsi label train:\")\nprint(y_train.mean())\n\nprint(\"\\nProporsi label test:\")\nprint(y_test.mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T01:15:07.243893Z","iopub.execute_input":"2025-11-26T01:15:07.244505Z","iopub.status.idle":"2025-11-26T01:15:07.426037Z","shell.execute_reply.started":"2025-11-26T01:15:07.244480Z","shell.execute_reply":"2025-11-26T01:15:07.425188Z"}},"outputs":[{"name":"stdout","text":"Proporsi label train:\nHS_Individual    0.271706\nHS_Group         0.151181\nHS_Religion      0.060358\nHS_Race          0.043126\nHS_Physical      0.024562\nHS_Gender        0.023324\ndtype: float64\n\nProporsi label test:\nHS_Individual    0.271896\nHS_Group         0.151181\nHS_Religion      0.060548\nHS_Race          0.043031\nHS_Physical      0.024752\nHS_Gender        0.023229\ndtype: float64\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nmax_words = 35000\ntokenizer = Tokenizer(num_words=max_words, oov_token=\"<unk>\")\ntokenizer.fit_on_texts(X_train)\n\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_test_seq  = tokenizer.texts_to_sequences(X_test)\n\nmax_len = 50\nX_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\nX_test_pad  = pad_sequences(X_test_seq, maxlen=max_len)\n\nnum_labels = y_train.shape[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T01:15:07.427470Z","iopub.execute_input":"2025-11-26T01:15:07.427777Z","iopub.status.idle":"2025-11-26T01:15:07.766716Z","shell.execute_reply.started":"2025-11-26T01:15:07.427760Z","shell.execute_reply":"2025-11-26T01:15:07.766074Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"import numpy as np\n\nembedding_dim = 300\nword_index = tokenizer.word_index\nembedding_matrix = np.zeros((max_words, embedding_dim))\n\nfor word, idx in word_index.items():\n    if idx >= max_words:\n        continue\n    if word in ft:\n        embedding_matrix[idx] = ft[word]\n    else:\n        embedding_matrix[idx] = np.zeros(embedding_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T01:15:07.767566Z","iopub.execute_input":"2025-11-26T01:15:07.767841Z","iopub.status.idle":"2025-11-26T01:15:07.854127Z","shell.execute_reply.started":"2025-11-26T01:15:07.767817Z","shell.execute_reply":"2025-11-26T01:15:07.853522Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.callbacks import Callback\n\ndef exact_match_ratio(actual, pred):\n    actual = np.array(actual)\n    pred   = np.array(pred)\n    return np.mean(np.all(actual == pred, axis=1))\n\ndef hamming_loss_(actual, pred):\n    actual = np.array(actual)\n    pred   = np.array(pred)\n    N, L   = actual.shape\n\n    diff = actual != pred\n    return diff.sum() / (N * L)\n\ndef micro_f1(actual, pred):\n    actual = np.array(actual)\n    pred   = np.array(pred)\n\n    TP = np.sum((actual == 1) & (pred == 1))\n    FP = np.sum((actual == 0) & (pred == 1))\n    FN = np.sum((actual == 1) & (pred == 0))\n\n    if TP == 0:\n        return 0.0\n\n    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n    recall    = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n\n    if precision + recall == 0:\n        return 0.0\n\n    return 2 * precision * recall / (precision + recall)\n\ndef macro_f1(actual, pred):\n    actual = np.array(actual)\n    pred   = np.array(pred)\n\n    L = actual.shape[1]\n    f1_scores = []\n\n    for j in range(L):\n        y_true = actual[:, j]\n        y_pred = pred[:, j]\n\n        TP = np.sum((y_true == 1) & (y_pred == 1))\n        FP = np.sum((y_true == 0) & (y_pred == 1))\n        FN = np.sum((y_true == 1) & (y_pred == 0))\n\n        precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n        recall    = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n\n        if precision + recall > 0:\n            f1 = 2 * precision * recall / (precision + recall)\n        else:\n            f1 = 0.0\n\n        f1_scores.append(f1)\n\n    return np.mean(f1_scores)\n\nclass MultiLabelMetrics(Callback):\n    def __init__(self, X_val, y_val):\n        super().__init__()\n        self.X_val = X_val\n        self.y_val = y_val\n\n    def on_epoch_end(self, epoch, logs=None):\n        y_prob = self.model.predict(self.X_val, verbose=0)\n        y_pred = (y_prob > 0.5).astype(int)\n\n        emr = exact_match_ratio(self.y_val, y_pred)\n        ham = hamming_loss_(self.y_val, y_pred)\n        mic = micro_f1(self.y_val, y_pred)\n        mac = macro_f1(self.y_val, y_pred)\n\n        print(f\" — val_exact_match: {emr:.4f} — val_hamming: {ham:.4f} — val_micro_f1: {mic:.4f} — val_macro_f1: {mac:.4f}\")\n\n        logs[\"val_exact_match\"] = emr\n        logs[\"val_hamming_loss\"] = ham\n        logs[\"val_micro_f1\"] = mic\n        logs[\"val_macro_f1\"] = mac","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T01:15:07.855872Z","iopub.execute_input":"2025-11-26T01:15:07.856070Z","iopub.status.idle":"2025-11-26T01:15:07.868958Z","shell.execute_reply.started":"2025-11-26T01:15:07.856055Z","shell.execute_reply":"2025-11-26T01:15:07.868416Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n\nmodel = Sequential()\n\nmodel.add(\n    Embedding(\n        input_dim=max_words,\n        output_dim=embedding_dim,\n        weights=[embedding_matrix],\n        input_length=max_len,\n        trainable=False\n    )\n)\n\nmodel.add(Dropout(0.25))\n\nmodel.add(\n    Bidirectional(\n        LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.2)\n    )\n)\n\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(num_labels, activation=\"sigmoid\"))\n\nmodel.compile(\n    loss=\"binary_crossentropy\",\n    optimizer=\"adam\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T01:15:07.869856Z","iopub.execute_input":"2025-11-26T01:15:07.870096Z","iopub.status.idle":"2025-11-26T01:15:08.016345Z","shell.execute_reply.started":"2025-11-26T01:15:07.870072Z","shell.execute_reply":"2025-11-26T01:15:08.015490Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"for train_idx, test_idx in sss.split(X_train_pad, y_train):\n    X_train_final = X_train_pad[train_idx] \n    X_val_final   = X_train_pad[test_idx]   \n\n    y_train_final = y_train.iloc[train_idx]\n    y_val_final   = y_train.iloc[test_idx] \n\n\nmetrics_callback = MultiLabelMetrics(X_val_final, y_val_final)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T01:15:08.017187Z","iopub.execute_input":"2025-11-26T01:15:08.017479Z","iopub.status.idle":"2025-11-26T01:15:08.142020Z","shell.execute_reply.started":"2025-11-26T01:15:08.017455Z","shell.execute_reply":"2025-11-26T01:15:08.141412Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"history = model.fit(\n    X_train_final,\n    y_train_final,\n    validation_data=(X_val_final, y_val_final),\n    epochs=10,\n    batch_size=64,\n    callbacks=[metrics_callback],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T01:15:08.142857Z","iopub.execute_input":"2025-11-26T01:15:08.143122Z","iopub.status.idle":"2025-11-26T01:15:09.020993Z","shell.execute_reply.started":"2025-11-26T01:15:08.143102Z","shell.execute_reply":"2025-11-26T01:15:09.020032Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/1421736156.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mX_train_final\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_train_final\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[0;34m(target, output, from_logits)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    768\u001b[0m             \u001b[0;34m\"Arguments `target` and `output` must have the same rank \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;34m\"(ndim). Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 6), output.shape=(None, 50, 6)"],"ename":"ValueError","evalue":"Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 6), output.shape=(None, 50, 6)","output_type":"error"}],"execution_count":74},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}